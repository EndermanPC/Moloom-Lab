{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/hyintell/BLOOM-fine-tuning.git\n",
        "%cd BLOOM-fine-tuning\n",
        "! pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "JoSQ1ogjWNdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import transformers\n",
        "from transformers import BloomTokenizerFast, BloomForCausalLM, TrainingArguments\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "from utils import ModifiedTrainer, tokenise_data, data_collator"
      ],
      "metadata": {
        "id": "82XYJ_shWYYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "tlPDS0uHWZIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"bloom-1b7\"\n",
        "model = BloomForCausalLM.from_pretrained(f\"bigscience/{model_name}\")\n",
        "tokeniser = BloomTokenizerFast.from_pretrained(f\"bigscience/{model_name}\", add_prefix_space=True)"
      ],
      "metadata": {
        "id": "Dd6q9xXRWbby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset('tatsu-lab/alpaca')\n",
        "input_ids = tokenise_data(dataset, tokeniser)"
      ],
      "metadata": {
        "id": "u-VDNxLOWdpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.gradient_checkpointing_enable()\n",
        "model.is_parallelizable = True\n",
        "model.model_parallel = True\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    \"output\",\n",
        "    fp16=False,\n",
        "    gradient_accumulation_steps= 1,\n",
        "    per_device_train_batch_size = 2,\n",
        "    learning_rate = 2e-5,\n",
        "    num_train_epochs=2,\n",
        "    logging_steps=10,\n",
        ")\n",
        "\n",
        "trainer = ModifiedTrainer(\n",
        "    model=model,\n",
        "    train_dataset=input_ids,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "CNfBLAxzWhKK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}